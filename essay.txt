1. Estimating individual treatment effect: generalization bounds and algorithms（2017）
  背景问题： 过去的因果推断研究大多集中在平均或群体层面的因果效应（ATE）上，而本研究专注于个体层面的因果效应（ITE），由于观测数据中存在混淆因素（Confounder），使得个体的治疗效果难以准确预测。*混淆因素：指调查而非实验数据可能会存在的样本分布偏倚问题，具体为X|t=0和X|t=1的分布不同，且X与t也可能存在因果关系。
  解决方案： 构建如下多任务网络结构，旨在学习平衡表征（balanced representation）。具体是在不加入处理t的信息的情况下先学得X的表征，之后用X的表征分处理构建预测网络，但是在表征处新加任务使得不同处理的X的表征分布更加接近，具体的目标为MMD或者W距离。
    方案反思： 该文章为平衡表征领域的经典文章，其通过限制不同处理的X的表征分布，使得不同处理的X都有相似的表征，减弱了调查数据所存在的混淆问题，对于后续处理的效应估计起到积极作用。该方法或者说该领域方法（平衡表征领域）都是为了减弱混淆问题所带来的处理效应偏差，大体思路就是加入正则来限制混淆因素的影响，本文利用了不同处理的X表征间的分布距离作为正则来限制。该方法也有一定缺陷，如多任务之间的权重分配不好确定、不好直接推广到多处理（多处理情况下有多个分布使得分布两两间距离计算冗杂）。notice：本文无code。
2. Learning Representations for Counterfactual Inference（2018）
  背景问题： 同1，针对Confounder问题（X|t=0和X|t=1的分布不同）。
  解决方案： 构建如下网络（示意图），本质上与1基本相同。在预测网络之外，文章还加入了两种正则化，其一是预测反事实结果，文章通过惩罚来鼓励反事实预测接近相反集（处理集或控制集）的最接近观察结果，其二是使得不同处理的表征分布相似或平衡（同1），文章通过减少一种分散距离（discrepancy distance）来实现。
    方案反思： 文章通过限制不同处理的X的表征分布，使得不同处理的X都有相似的表征的思路与1相同，都尽量减弱混淆问题，对于效应估计起到积极作用；而预测反事实结果的思路类似X-learner，使得不同处理间的预测网络能有所交互，对于后续效应估计有积极意义。本方法的缺陷一部分与1类似，1中的多任务之间的权重分配不好确定、不好直接推广到多处理问题依旧存在，此外预测反事实结果中，训练时需要找到样本的反事实标签，文中方法是选取表征最接近的样本，但是这一思路一方面可能存在偏差，另一方面只适合特征较少，表征维度不大的场景，不然反事实标签很难查找。notice：本文无code。
3. Estimating Individual Advertising Effect in E-Commerce（2019）
  背景问题： 通过建模整体广告回报并估计广告预算与回报之间的因果效应，使广告主能够更明智地分配广告预算，本文更针对因果效应预测问题。
  解决方案： 整体框架与1相似，但是在训练loss中，本文用不同处理的样本数对每个样本的预测误差做了加权，具体的形式不做赘述，但是这样的loss最小化了PEHE（Precision in Estimation of Het-erogeneous Effect）的名义loss，使得模型对因果效应的估计更加精准。
  方案反思： 通过对loss的改进，本文模型很好地改进了模型对因果效应的估计，原因在于之前的模型更多是单纯以预测误差为loss，忽略了不同处理的信息，而将这一信息加入loss部分使得模型学习能力更强。本文缺陷：loss的trade-off问题，新的loss在总loss中的占比不好确定；目的专一，估计因果效应，对以预测精度为主的目标可能不合适。
4. Estimation of causal effects with multiple treatments: a review and new ideas（2017）
  背景问题： 当前多处理的因果效应估计方法存在分散和不易访问的问题，多处理因果效应需要统一指标、找到规范的建模方法。
  解决方案： 提出向量匹配（VM）模型，通过倾向分的max（min）和min（max）的形式构建每个处理的支撑，用于从各个处理的样本中匹配相似的样本来填充反事实样本集。
  方案反思： 本文在多处理的情景下提出了倾向分的使用方式，用于反事实样本的匹配。这种匹配可以辅助减弱混杂因素的影响，但是在深度学习场景下面临表征维度大，反事实样本匹配困难的挑战，后续的改进是必要的。
5. Adapting Neural Networks for the Estimation of Treatment Effects （2019）
  背景问题： 混杂因素在因果效应中的影响。
  解决方案： 1. 构建如下网络，Z为X的表征，多任务架构中添加用X预测处理T的预测网络，预测网络为简单线性分类网络，旨在表征中分离出confounder；2. 采用命名为targeted regularization的正则化技术，具体来说是在损失中加入分类网络输出和效应预测网络输出的epsilon聚合与真实y的MSE，出发点为取得渐进最优的psi(ATE)。
    方案反思：文章网络的构建旨在建模出X对t的预测，进而达到类似解耦的目的，将X中的confounder解耦出来，这样可以有效地避免X样本分布不均的问题。然而文章的另一个改进在求得更有相合性和稳健性的ATE的出发点下，构建了新的损失，这事实上就是训练一个模型仅仅从和当前T相关的表征上来预测Y ，这么做可能会造成对于Y的预测的损失，而在我们的场景中，更关心的是预测精度而非ATE的估计，故这一部分我们可能不太需要，此外，该损失的多处理形式尚需较高阶数学推导，暂无合适方案。
6. Learning end-to-end patient representations through self-supervised covariate balancing for causal treatment effect estimation （2023）
  背景问题： 混杂因素在因果效应中的影响，传统的因果推断方法通常采用平衡分数或加权方法来调整观察数据中的协变量。
  解决方案： 模型架构如下，事实上和dragonnet相同。但创新点在于改进了倾向分模型的loss，之前dragonnet用的是分类损失（BCE），但BCAUSS更换为如下损失。
      方案反思：本方法是开源数据集IHDP的因果效应估计sota，dragonnet的分类损失旨在解耦X的表征，而BCAUSS的损失则会使得X的表征在不同处理下分布更加平衡，起到了与IPM方法异曲同工的效果，推广到多处理形式的方式有一定困难，但是不得不说值得思考。多处理使用IPM方法往往会因为处理过多，分布距离两两对应太多，一个batch_size塞不下足够数量的各个处理的样本等问题，BCAUSS提供了一个不一样的解决方案，从解耦特征的倾向分模型出发，得到了表征平衡的结果，且实验证明是sota，值得反思其创新之处。
7. Double/Debiased/Neyman Machine Learning of Treatment Effects （2017）
  背景问题：机器学习方法下的ATE估计。
  解决方案：基于ATE和ATTE预测性能优化目标，根据数学理论推导构造出Neyman正交条件下的优化目标，该目标函数作为了Dragonnet的targeted regularization的损失函数。
  方案反思：精读Dragonnet论文过程中感觉targeted regularization推广到多处理情景下有较大困难，故在这篇reference中查找原理，其根据ATE和ATTE预测性能的优化目标导出了具有优异性质的损失函数（对混杂的一阶导数为0）。然而在多处理情形下，单纯推广其损失形式没有数学意义，本地实验验证效果为负，一种思路是处理两两构造targeted regularization损失，但这样不太现实，和CFRnet有相似的推广难题，不易推广到多处理情形。



1. A SURVEY OF DEEP CAUSAL MODELS AND THEIR INDUSTRIAL APPLICATIONS（2022）
  问题背景：深度因果推断模型综述，总结因果推断领域的问题和研究现状，为之后的方向提供参考。
  文章内容：深度因果推断模型主要就是为了解决混杂因素confounder的问题，处理方向分为：平衡表征（Representation of distribution balance）；协变量混杂学习（Covariates confounding learning）；基于生成式对抗网络（GAN、VAE）；以及时间序列因果估计等。其中平衡表征的方向以经典的BNN（2016）、CFRNnet（2017）等为代表，旨在利用控制/处理组的表征间的分布构建损失，目标学习到平衡的表征；协变量混淆学习包括经典的Dragonnet（2019）以及近来的一些协变量解耦方法（DR-CFR（2021）等），旨在通过自监督方法（x预测t）解耦出混淆协变量；基于生成式对抗网络的方法从经典的GANITE（2018）开始，从生成反事实样本到利用潜在隐变量平衡表征。
  内容反思：在我们的场景下，平衡表征方法较难应用，原因在于其推广到多处理时分布数量多难以计算散度，后续可以查找当前有无推广好的方案；协变量混杂学习是比较好实践的方案，从Dragonnet到BCAUSS等，其模型不受处理个数限制，但是难点在于如何推广单处理情况下的损失函数；基于生成式对抗网络的方案也可以作为后续推进方向，目前尚未实践。

2. CETransformer: Casual Effect Estimation via Transformer Based Representation Learning（2021）
  问题背景：如何将Transformer应用于因果推断深度学习模型中。
  文章内容：提出如下网络结构，输入的X经过Transformer进行特征提取，之后分别经过三个下游，形成三个损失，分别为：经过全连接层重构X，与原先的X形成比较损失（MSE）；分组（控制/处理）比较分布距离形成表征平衡损失；用表征预测y形成预测损失。三个损失进行trade-off即构建成最终网络。
    内容反思：该文解决的主要是在因果推断深度网络中使用Transformer进行特征提取，由于Transformer需要大量数据进行训练，一般都在可以自监督学习的领域中使用（CV、NLP等），但是本文采用了重构损失，旨在控制Transformer提取的表征和原先的X间的gap尽量小，不仅使得Transformer在样本量不大的情况下可以训练，而且可以得到更加稳定的Transformer特征表征。但本文采用了分布距离损失，这在多处理情景下不好推广，在应用中，可以将Transformer的特征提取部分抽离出来使用，分布距离损失可以使用协变量混杂学习进行替代（Dragonnet、BCAUSS等）。

3. Exploring Transformer Backbones for Heterogeneous Treatment Effect Estimation（2022）
  问题背景：此前因果网络都是用MLP进行连接，本文希望利用更先进的Transformer进行替代。
  文章内容：基于之前的研究构建了TransTEE模型结构，旨在用Transformer进行特征提取，针对t有额外的信息的情况，同时提取x与t的表征，其中x的表征一方面进入一个协变量混杂学习任务计算损失，另一方面和t的表征一起预测y并计算分类/回归损失。这种方法在多处理情形下参数量不变，是一个很好的针对多处理情形的网络，采用了Transformer架构使得其提取特征能力增强。
    内容反思：本文的TransTEE架构很好地适应了多处理场景，且处理量很大时也不需要额外的参数，而额外的t特征提取模块使得t的特征重要性可以得到提高；另一方面，本文架构也很好地嵌入了协变量混杂学习任务，本任务在多处理情景下可以由分类损失等构成。但是本文的场景仅在t本身携带额外信息时适用，t仅仅为标签的情况下很可能会导致t特征提取模块无法提取到有效信息，且Transformer的训练可能需要很多数据，在不加约束的情况下用少量样本训练Transformer可能会导致表征过拟合、无法训练等问题。鉴于上述问题，本文方法可以等业务中接入处理特征后进行实践。

4. Counterfactual Prediction for Bundle Treatment（2020）
  问题背景：高维处理情况下（例如处理t为高维的二值向量的集合，即不同的处理可以同时激活），如何分离confounder和X以对因果效应进行更好的估计。
  文章内容：基于变分理论提出如下的VSR模型，假设原始处理（高维的t）是由一个低维的潜变量生成，使用VAE去学习潜表征，并推导出基于神经网络的密度比估计来分离X和Z，通过汇总潜变量的整个变异分布中的密度比来计算样本权重的分布，而不是点估计，之后用真实的z|T（L=1）和采样的z（L=0）训练二元分类任务p（L|x,z），最后预测阶段通过q（z|T）加权得到最终输出。
    内容反思：本文的VSR模型利用隐变量思想将高维处理进行降维估计，在bundle情况下，treatment的组合有2^p之多，用较低维的潜在变量z可以使得模型变得更可估，简化模型的同时提高模型的鲁棒性和泛化性能。但是本文场景是在推荐系统下高维处理场景的一种处理方案，放在当前业务中（多处理但同时只有一个处理被激活）不好实际应用，且没有开源代码，尝试手写模型但训练时发现损失波动大，可能是VAE部分的代码有所欠缺。

5. Estimating Average Treatment Effects via Orthogonal Regularization（2021）
  问题背景：因果效应估计中，过去的方法主要基于无混淆性来估计结果，但忽略了无混淆性对结果的约束。
  文章内容：本文提出了一种新的正则化框架，利用无混淆性约束来估计平均处理效应，通过将正交性约束纳入损失函数中，开发了深度正交网络（DONUT），该网络学习与处理分配正交的结果。通过使用多个基准数据集来估计平均处理效应（ATE）。作者提出的正则化框架称为正交正则化（OR），通过将无偏性形式化为正交约束来解决现有方法的缺点，该约束包含在模型参数的估计中，实践中将OR损失加入先前的框架中（本文中为Dragonnet），OR部分确保结果与治疗分配正交，包括伪结果和扰动函数，以学习与治疗分配正交的结果。
  内容反思：本文在Dragonnet基础之上，加入了正交约束，实际代码实现为在通常的损失的基础上加入当前模型的ate估计的约束损失，即y_true - t_true * psi - y0_perd的平方和，其中psi是当前模型对于输入数据batch的ate估计。本文正交损失的思想是在传统模型基底上加入正交损失，这对于ate的估计有一定帮助，推广至多处理情形的损失形式不太好推导，只能采用多组实验验证新损失的效果。

6. On Inductive Biases for Heterogeneous Treatment Effect Estimation（2021）
  问题背景：本文关注在潜在结果框架中估计条件平均处理效应（CATE）的问题，流行的间接学习器（如T-learner和TARNet）中存在隐含归纳偏差，这些偏差鼓励了处理效应的异质性。
  文章内容：提出如下基于前述模型的FlexTENet，模型将共享机制由shared bottom变为多链形式，并且设计了三种参数惩罚形式以消除隐含归纳偏差，分别为软方法（对输出头部的权重差异进行正则化）、硬方法（重新参数化潜在结果函数）以及本文所使用的灵活方法（学习在每个网络层中PO函数之间的共享信息）。
    内容反思：本文旨在解决之前的因果效应模型中存在的归纳偏置的问题，在这一问题的解决思路上，作者采用了通过正则化平衡不同的PO网络之间差距的思路，这一思路的实现中，作者采用了三种方式，其本质分别为之间约束最后的输出层以平衡PO网络的差异、每层都进行正则化平衡、以及构造中间层进行信息共享来约束PO网络差异。在我们的业务场景应用中，原本的baseline的输出层就为MMOE，其本质上也使得各个输出头之间有所交互、约束，本文的思路和我们的模型有异曲同工的效果，但本文思路的约束我们并没有添加，如果以增强CATE估计为目的，该方法有一定的实践价值。

7. Learning Decomposed Representation for Counterfactual Inference（2021）
  问题背景：针对因果模型中x的混杂形式不确定，试图通过提出混杂形式假设来增强模型推理能力。
  文章内容：假设x、t、y以及混杂因子存在如下关系形式，其中X可以被拆分为I（工具变量，只与t相关），A（调整变量，只与Y相关）以及C（混杂变量，同时与T和Y相等）。基于此假设，作者提出了一种名为DeR-CFR的方法，用于对照事实推断。该方法利用表示网络对工具变量、混淆变量和调整变量的特征信息进行分解。通过使用深度正交正则化器来确保这些因素的分解。该方法还包括用于估计治疗效应的结果回归模型。DeR-CFR算法的目标函数被最小化以优化表示和样本权重。该方法可以通过在分解过程中对其进行二值化来应用于连续或多值治疗和结果。
    内容反思：本文的动机是解决观测研究中混淆因素识别和平衡的问题，通过如上的假设，作者构建出了带有正则化的网络，以先验知识约束网络来让网络朝预期结构训练，这样一定程度上能够缓解混杂变量的问题，增强模型对因果效应的估计能力。在实践中，多处理场景下我们较难去约束A和T以及I和Y的关系，初步考虑可以用相关性或者互信息等损失进行训练，具体效果需要实验来验证。

8. DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect Estimation（2022）
  问题背景：传统上，个体化治疗效果估计（ITE）是通过分别建模治疗组和对照组的响应函数来预测的，而分布有偏性限制了个体化治疗效果估计的准确性和可靠性。
  文章内容：提出了如下所示的DESCN模型。该模型由两个组件组成：整体空间网络（ESN）和X-network。ESN用于估计治疗和对照子样本空间上的治疗响应（TR）和对照响应（CR），X-network结合了ESN估计的响应来计算ITE。该模型旨在解决ITE估计中的治疗偏倚和样本不平衡问题。
    内容反思：DESCN通过一个多任务交叉网络从整体空间的角度建模治疗效果，具体来说，其通过在整个样本空间中联合学习治疗和响应函数，避免了治疗偏差，并利用中间的伪治疗效果预测网络来缓解样本不平衡问题，这样使得个体治疗的估计具有较好的精度。其中X-network的结构很像没加约束的DeR-CFR，这对我们的实际应用有所启发。这和我们的MMOE架构也有一定相似，理论上都是使得所有的PO网络（潜在输出网络）在各个处理下的样本都能进行训练，同时采用了伪治疗效果预测网络来平衡上述操作带来的误差，双重确保了个体治疗效果的估计，但不排除存在误差累积的可能性。

9. SCI: Subspace Learning Based Counterfactual Inference for Individual Treatment Effect Estimation（2021）
  问题背景：现有的表示学习方法侧重于学习一个平衡的特征空间（representation ），忽略了与结果相关的某些预测信息。
  文章内容：提出如下SCI网络结构，针对两处理场景，X首先输入三个并行的子空间，分别生成处理组、控制组和公共表征，其中处理组和控制组分别进行潜在输出预测，公共表征组进行表征平衡处理，并与其他两组表征分别拼接后经过重构和潜在输出两个输出头网络。损失包括子空间预测损失（伪差异损失），公共空间表征平衡损失，重构损失以及最终潜在输出损失。
    方案反思：本方案的切入点在于传统的表征平衡往往是在以ATE估计为目标，若以ITE估计为目标时，单纯的表征平衡忽略了与结果相关的某些预测信息，会使得个体效应估计有偏，故本文在平衡表征的路线外并行加入了各个组的子空间表征学习，该表征以预测真实值为目标进行训练，之后与公共子空间拼接后进行最终预测，同时用重构X来限制预测表征的训练。本文方法可以推广到多处理场景，推广时具体的子空间个数与任务个数需要实验确定，此外其多任务并行的结构与MMOE可以适配，但有所差异，其任务类型不同可能带来负迁移效应，故引入下一篇论文方法的应用。

10. Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations（2020）
  问题背景：多任务网络训练中，通常存在松散相关性甚至冲突，这可能导致性能下降，即负迁移效应，这导致了任务间训练冲突的跷跷板效应。
  文章内容：提出如下PLE模型，其通过分离共享组件和任务特定组件，并采用渐进路由机制来解决MTL模型中性能退化和负迁移的问题。具体来说，PLE在MMOE的基础上，为每个任务额外添加了一个expert，使得任务间的精度可以不受彼此的限制，提高多任务共同学习的精度上限。
    内容反思：在MMOE可能存在的负迁移效应背景下，PLE为每个任务多加了一个expert。实践中可以理解为额外从表征到任务输出头加了一个MLP，其内核类似于残差链接，旨在通过额外参数的设置避免多任务之间的训练互相牵制过多，这样提高了多任务模型的整体上限。

11. Counterfactual Representation Learning with Balancing Weights（2021）
  问题背景：针对分布不均处理方法中的表征平衡和预测能力之间的权衡问题。
  文章内容：基于加权思想（IPW）与表征平衡相结合，提出使用平衡权重的方法来改善表示学习效果的模型BWCFR。该模型为两阶段模型，先训练一个倾向分模型，再基于倾向分模型的结果进行类似IPW方法的预测加权训练方法，同时对表征进行IPM平衡训练，且在IPM训练时也加入权重影响。其中IPW加权方法分为基础IPW、MW、OW和TruncIPW，三个方法都是在IPW基础上加上倾斜权重，其中TruncIPW为本文首创，本质上为一个截断函数，对于倾向分过大即判断过于绝对的样本进行去除（权重设为0）。
  内容反思：本文将IPW与表征平衡相结合，在IPW的基础上加入以IPW方法计算的表征平衡损失，相当于在CFRnet的基础上将其损失的两个部分（即预测损失和表征平衡损失）都以倾向分进行加权。实践中为两阶段建模，一阶段进行倾向分建模，二阶段冻结一阶段模型，进行IPW下的预测损失训练和表征平衡训练。

12. Deep Interest Network for Click-Through Rate Prediction（2018）
  问题背景：推荐模型在表示用户兴趣方面存在瓶颈，无论候选广告是什么。用户兴趣的表示向量需要大幅扩展以表达多样的兴趣，但在工业在线系统中是不可行的。
  文章内容：基于如下图左的base模型提出下图右的DIN模型，在base模型对用户历史行为的特征提取基础上。DIN引入局部激活单元来通过考虑给定候选广告的历史行为的相关性来自适应地计算用户的表示向量，该单元对历史行为的相关部分进行软搜索，并取加权和以获得用户的表示向量。
    内容反思：本论文是推荐模型系列中对用户历史行为序列建模的经典论文，所提出的DIN模型也是之后许多模型的参考原型。传统的base模型中，对用户历史行为的建模并没有与候选物品做交互，而两者交互可以对物品的选择起到重要作用，而交互方式采用了Attention方式，交互所得结果作为行为的权重，这样更好地提取了基于用户行为历史的候选物品兴趣特征。在我们的长期因果模型中，用户长期的行为序列可以采用类似的方法进行倾向提取、激活预测等。

13. Deep Interest Evolution Network for Click-Through Rate Prediction（2019）
  问题背景：过去的点击率预测方法大多将行为的表示视为兴趣本身，缺乏对具体行为背后潜在兴趣的特殊建模。此外，很少有研究考虑兴趣的变化趋势。
  文章内容：提出如下的DIEN模型，其采用GRU对用户的历史行为进行编码，每个时间步会产生该消费者对应时间点的兴趣隐状态表示，并且引入了一个辅助loss来更好的学习每个时刻的隐状态表示。此外，模型使用GRU每个时间步输出的隐状态表示和待预测广告的表示做Attention得到Attention score，这个score反映了哪些状态是和当前广告相关的，筛选掉了不相关的历史行为，减弱不想管历史行为隐藏状态的更新强度，实现了与广告更相关的那些兴趣态能够更大力度的更新演化序列的隐状态表示的目的。
    内容反思：DIEN对DIN的不足进行了改进。首先，DIN中直接利用历史行为的商品ID作为全部信息输入，但是商品ID只是表象，背后蕴含着品牌、类目等隐性信息，只用商品ID的表象信息是不足的，需要提取内在的隐性信息更充分理解用户历史行为。其次，DIN中提出序列建模（如RNN建模历史行为序列）效果不好，这其实是因为历史行为序列的随机性较大，消费者在电商平台看到的东西同时属于多种类型，序列中不同类型的节点跳变随机性强。而如果能直接筛选出和当前待预测点击率的广告相关的历史行为组成新的序列，那么就能更清晰的描述出用户在这个类型兴趣下的行为演变。

14. Deep Session Interest Network for Click-Through Rate Predictiond（2020）
  问题背景：大多数现有研究忽视了序列的内在结构，即序列由会话组成，而会话是用户行为按照发生时间分隔的。然而，我们观察到每个会话中的用户行为非常相似，而会话之间则存在差异。现有的点击率预测模型往往没有充分利用用户的多个历史会话。
  文章内容：提出如下DSIN模型，通过利用用户的多个历史会话来模型用户的序列行为。DSIN模型首先使用自注意机制提取每个会话中的用户兴趣，然后使用时间序列模型建模用户兴趣在会话之间的演化和交互。最后，使用局部激活单元自适应地学习各个会话兴趣对目标项目的影响。具体来说，DSIN在每个session内部的历史行为使用Multi-head Attention进行建模，最后求平均得到每个session块的兴趣表示。进一步使用双向LSTM，以每个session的兴趣表示作为输入，对session之间的关系进行建模。最后根据当前的待预测信息使用Attention进行一步对齐操作（类似DIN），最后拼接到其它特征上。
    内容反思：DSIN相比DIN的改进主要是对用户历史行为部分的建模更加精细化了，分session建模，得到的每个兴趣的表示更加丰富，而不像DIN只使用商品的ID embedding。但是这个分session的操作可行性还需具体看待，不过文章所用的多层次注意力机制的使用可以进行实践尝试。

15. Wide & Deep Learning for Recommender Systems（2016）
  问题背景：传统的DNN能将高维稀疏特征编码为低维稠密的Embedding，但是这种方式会使得不同特征用相同方式进行交互，损失特征的深层信息。
  文章内容：提出如下Wide & Deep模型框架，模型分为Wide部分和Deep部分，其中Wide部分实质是一个广义线性模型，Deep部分是一个前馈神经网络，通过将Wide模块和Deep模块的对数加权输出作为预测值，然后送入损失函数中，用于联合训练。该方法将不同特征输入不同的特征提取部分，对于简单特征直接输入最终预测层，对于复杂特征（如序列特征等）先进行深度网络进行特征提取再与简单特征concat后输入到最终预测层。
    内容反思：基于Embedding的方式可能因为数据长尾分布，导致长尾的一些特征值无法被充分学习，其对应的Embedding是不准确的，这便会造成模型泛化过度（过拟合）。Wide & Deep通过将不同特性的特征输入到不同网络部分，使得模型更能关注输入数据的长尾部分，增加长尾特征（如行为序列特征）的特征重要性。该方法很好地契合了我们提升用户历史行为序列特征重要性的目标，实践中，通过修改行为序列特征交互后的深度特征的concat位置，我们可以提升该部分特征的影响力，进而使得模型对该部分特征的重视程度。

16. PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information（2023）
  问题背景：传统的推荐模型问题中，多任务和多领域推荐的核心是在给定多个用户行为的情况下准确捕捉用户在多个场景中的兴趣，而某些重要特征的长尾分布是导致这一问题的一大原因。
  文章内容：文章提出如下的PEPNet模型，该模型将个性化的先验信息作为输入，并通过门控机制动态调整底层嵌入和顶层DNN隐藏单元。通过注入个性化的嵌入选择和个性化的DNN参数修改，PEPNet根据每个个体的兴趣获得了显著的性能提升。其中，PEPNet分为EPNet和PPNet两个部分，其中EPNet进行基础特征和多领域特征的表征交互，而PPNet将长尾分布的先验重要特征进行表征提取，之后用作门控机制，与主网络中的每一层进行点乘。
    内容反思：EPNet部分暂时没有实际场景。PPNet思路与Wide&Deep类似，不同的是其使用了门控机制而非直接将表征进行concat，实际上类似于使用注意力机制的点乘方式。该方法将一些先验认为重要的强bias的特征，放到裁判的位置，决定其他特征的重要性。在实际使用时，由于PPNet将其他特征的表征也进行concat，但是在我们的场景中其他表征维度较大，全部concat会使得门控表征维度过大，故我们可以仅使用先验长尾特征的表征用作门控处理，或是使用注意力机制进行降维处理，对于序列特征也可以尝试Transformer Encoder进行表征提取。

17. MEMENTO: Neural Model for Estimating Individual Treatment Effects for Multiple Treatments（2022）
  问题背景：大多数现有的个体治疗效果研究主要集中在二元治疗方案上，并没有自然地扩展到多个治疗方案的情况。
  文章内容：本文提出了一种方法来估计个体级别的治疗效果，其中治疗方案是离散且有限的，算法称为MEMENTO。该方法基于通过最小化实际损失和反事实损失之和的上界来获取各种治疗类型的混淆因子的匹配表示，具体而言，该论文证明了损失之和的上界与潜在输出损失和潜在表征的分布差异之间的关系式（与TARnet类似）。实践中，其网络结构即为多处理TARnet的架构，其损失包括按倾向分逆向加权的潜在输出分类/回归损失，参数正则项以及不同处理之间表征的MMD损失。此外，文章还提出了一种基于不确定性对潜在预测进行剪枝的方案，该不确定性（方差）通过推断时加入dropout进行计算。
    内容反思：本文是Amazon提出的多处理因果效应估计算法实践，该方法基于二元处理TARnet的理论，拓展了多处理场景下实际损失和反事实损失之和的上界，并通过损失以最小化该上界。从结果来看，本文的方案就是基于倾向分对损失进行逆加权训练+潜在表征的分布差异损失（MMD），该模型理论上需要两个模型进行先后训练，先进行倾向分模型训练，后进行TARnet训练，实践上也许可以同时训练。此外，该算法的基于方差的剪枝思想另辟蹊径，由于推断时模型参数固定，不具有不确定性，文章在推断时加入dropout使得推断具有不确定性，进而计算出方差进行剪枝控制。该方案存在实践可行性，其思想或许可以融入模型的下游策略。

18. Learning Disentangled Representations for Counterfactual Regression via Mutual Information Minimization（2022）
  问题背景：如何准确学习潜在的解耦因素仍然是一个开放的问题。先前的方法未能获得独立的解缠结因素，这是确定处理效应的必要条件。本文为阿里发表在ACM的营销场景因果推断文章。
  文章内容：提出最小化互信息实现解缠结表示的反事实回归（MIM-DRCFR）解耦框架，思路如下图，旨在通过学习输入特征的解缠结表示来估计治疗效果。该方法包括多任务解缠结表示学习层、互信息最小化正则化器和表示层正交性准则等多个组件。具体而言，该模型数据场景为营销推荐场景，模型将用户特征、用户行为序列特征、其他特征进行嵌入拼接并生成了三个表征，即gamma、delta、upsilon，其中通过前两者进行处理的估计，通过后两者进行潜在输出的估计，并对upsilon进行正则化，正则方式为IPM，即传统的根据处理进行的表征平衡项。
    内容反思：该模型的解耦思路与DeR-CFR如出一辙，但不同的是由于其场景为营销场景，其采用了将多种特征一起进行嵌入拼接后，进行中间隐层解耦的思路，三个解耦表征的假设和DeR-CFR一样，第一个表征只和倾向分预测相关，第二个表征是混杂因素，与倾向分任务和潜在输出任务都相关，第三个表征只和潜在输出有关，根据假设，需要对第一个和第三个表征进行相关性正则化，而本文只对第三个表征进行了正则化，方式是IPM，没对第一个表征进行惩罚的原因可能是兼顾模型稳定性。本文框架可以和其他方法进行兼容，很适合作为基础网络。

19. Learning Latent Causal Structures with a Redundant Input Neural Network（2020）
  问题背景：因果发现是一种从数据中学习因果关系的机器学习方法，但大多数方法只能发现观测变量之间的因果结构，对于潜在变量之间的因果结构的学习仍然是一个重要的问题。
  解决方案：提出如下RINN模型，该模型通过直接连接输入变量和潜在变量，从而学习输入变量与任何潜在变量之间的直接因果关系。具体而言，其在不加公共表征提取层（shared embedding）的T-learner基础上，额外让每一层的潜在变量都与最初输出x直接链接，利用类似残差链接的方式使得x能够进行多阶交互，从而学习输入变量与潜在变量之间的关系。此外，本文可视化了不同深度学习策略和距离度量中的权重，以评估深度学习策略和找到因果结构的效果。
    内容反思：本文针对因果效应不明确的场景，通过修改架构和正则化目标函数，可以找到输入、隐藏和输出变量之间的因果关系。模型整体思路类似于DCN和DeepFM，本质上像是让x与隐层表征进行交互从而提取出高阶交互特征，从而提升模型的表征提取能力。对于我们的场景来说，由于因果效应是默认存在的，且在不同处理组间不同，故该模型对我们的启发就是通过高阶特征交互来提升模型的表达能力。

20. Cost-effective incentive allocation via structured counterfactual inference.（2020）
  问题背景：针对现代市场营销活动中的一个实际问题，即中央代理商如何学习将战略性财务激励分配给客户（处理选择），并仅观察到有限的反馈信息。以往的反事实推断方法在处理结构化奖励方面存在局限性，并且在行动空间的基数较大时不太适用。
  文章内容：本文考虑了该设置中常见的附加奖励结构和预算约束，并提出了一种新的两步方法来解决这个约束的反事实策略优化问题。该方法称为通过结构化激励响应估计的约束反事实策略优化（CCPOvSIRE），该方法考虑了分配过程中的奖励结构和预算约束（基于Bandit方法）。该方法首先使用领域适应方法和补充结构来估计激励响应，然后使用估计器对策略进行带约束的优化，实践时损失为常规输出损失+IPM损失，而IPM损失用HSIC来计算。
  内容反思：本文为蚂蚁的营销模型实践，我们关注的因果部分中，其采用了由HSIC计算的IPM损失，我们可以借鉴其思想，用其代替MMD或W距离损失，理由在于多处理场景下，长尾分布会使得分布差异计算不稳定，用HSIC可以达到类似效果，且表征提取整体无偏。



1. Deep IV: A Flexible Approach for Counterfactual Prediction（2017）
  问题背景：传统的机器学习方法在处理因果推断问题时存在一些限制，例如无法处理选择性偏差和未观测到的潜在变量等问题。
  文章内容：提出一种灵活的方法，通过使用工具变量来解决因果推断问题，并利用深度学习方法来实现准确的预测。通过这种方法，可以更好地理解和预测干预的效果。具体而言，其通过寻找到协变量中仅与处理相关的变量作为工具变量（IV）z，假设存在如下因果图关系，提出两阶段模型Deep IV，模型框架涉及两个预测任务：用于治疗预测的第一阶段网络和整合条件治疗分布来预测潜在输出的第二阶段网络。文章强调了使用现成的监督学习技术来估计因果效应的优势。
    内容反思：本文在假设能找到协变量x之外（或者从x中分离出）的仅与处理偏向有关的工具变量z，并基于z和x进行了两阶段模型来分别推断处理选择t与潜在输出y，模型运用了统计学思想，在因果关系中加入工具变量使得模型稳健性大幅上升，因果效应预测精度也有所提高。但是本文模型的弊端也十分明显，在建模准备时需找到仅与处理选择的工具变量z，这在实际运用的时候有较大困难，在开源数据集上也是先进行特征选择在进行建模，整体效果受到特征划分的影响较大。

2. Causal Effect Inference with Deep Latent-Variable Models（2017）
  问题背景：过去的方法通常通过控制混淆因素来解决因果关系的推断问题。然而，如果混淆因素是隐藏或未测量的，通常无法在一般情况下（即没有进一步的假设）估计干预对结果的影响。
  文章内容：本文讨论了从观测数据中学习个体层面因果效应的问题，重点是处理混淆因素。作者提出了一种基于变分自动编码器的方法，同时估计总结混淆因素和因果效应的未知潜在空间，即构建如下因果图（CEVAE）假设，并用VAE方法对隐变量z进行推断，用于学习混淆因素和因果效应的潜在空间。该方法显示出比现有方法更具鲁棒性，并在先前的基准测试中实现了最先进的性能。

    内容反思：该方法为将VAE方法应用于因果效应模型的先例，其基于先验因果假设构建隐变量因果图，通过VAE进行隐变量z的推断，构建一个联合模型，同时估计混淆因素和因果效应。实践时，该模型通过最大化因果效应的似然函数，优化模型参数，得到最终的估计结果。该模型不同于IV、解耦方法，构建了隐变量因果图，推断方法可能不够稳健，其效果也未达到很好的程度，但却是较好的待优化基底。

3. Learning Overlapping Representations for the Estimation of Individualized Treatment Effects（2020）
  问题背景：过去的方法主要集中在学习对干预策略具有域不变性的表示（表征平衡），以实现对实际数据的预测。然而，本文指出域不变性往往是一个过于严格的要求，而重叠支持是确定因果效应和密度相等性的充分条件。
  文章内容：本文提出了反事实估计模型DKLITE（用于个体化治疗效果的深度核学习），它在由神经网络参数化的非线性映射函数φ引导的特征空间中工作。该模型使用深度核来建模特征空间中输入之间的相关性。假设给定个体协变量的潜在结果采用特征表示的线性组合形式。通过先验分布来指定权重向量和噪声变量。使用正则化贝叶斯框架来学习接近真实后验的后验分布，同时满足正则化项所要求的要求。通过边缘化后验获得测试点的预测分布。通过最小化负对数似然来优化实际数据的似然性，并将反事实方差作为正则化项，以鼓励实际数据和反事实数据的表示之间的重叠。
  内容反思：本文通过学习重叠表示和保留底层上下文信息的可逆表示，提高个体化治疗效果的估计性能。本文指出域不变性往往是一个过于严格的要求，传统的IPM损失往往不合实际，而重叠支持是确定因果效应和密度相等性的充分条件。通过引入后验方差的正则化准则，本文提出了一种优化框架，并在多个基准数据集上进行了实验验证。

4. Learning Conditional Instrumental Variable Representation for Causal Effect Estimation（2023）
  问题背景： 因果效应估计经常受到混淆偏差的影响，该偏差由同时影响处理和结果的未测混淆因素引起，找到有效的混杂因素的因果图假设对因果效应建模很有帮助，此外针对工具变量的使用，现有的基于工具变量（IV）的估计器需要提供一个指定的IV，对于条件IV（CIV）还需要提供相应的条件集，这限制了IV-based估计器的应用。
  文章内容：本文基于如下左图(c)的因果图关系假设（(a)为最基础假设，(b)为基于IV的假设），通过利用解缠表示学习（X解耦为S、C、F），其中S（表示仅影响处理变量的CIV）、F（表示影响结果变量的风险因素）和C（表示影响处理和结果变量的混淆因素），并且引入了条件工具变量（CIV）的概念，本文提出了一种新方法DVAE.CIV，用于从具有潜在混淆因素的数据中学习和解缠CIV的表示以及其条件集的表示，以进行因果效应估计。这项研究的动机是解决因果效应估计中的混淆偏差问题，并提供一种更广泛应用的IV-based估计器。
    内容反思：本文融合了解耦法、工具变量法以及VAE，将解耦的变量当作条件工具变量（CIV），并假设了一个潜在变量W，其与其他变量存在因果关系如上左图，使用VAE对其分布进行拟合推断，最终构建出较复杂的组合模型。该模型利用了不同方法的优势，并将其模块化，使得最终的模型具有较好的拟合能力，但同时也正是因为模型复杂度较高，其过拟合风险较大，在简单数据集上原文使用减小隐层维度来对冲，实际中调优可能存在一定难度。

5. Learning Infomax and Domain-Independent Representations for Causal Effect Inference with Real-World Data（2022）
  问题背景：过去的文献已经探索了基于不同领域分歧度量（如MMD、W距离等）的领域无关表示学习方法（表征平衡法），但这些方法存在一些弱点，如在强制领域不变性时丢失预测信息，以及治疗效应估计性能不稳定，严重依赖于领域分布的特征和领域分歧度量的选择。
  文章内容：提出如下模型IDRL，该模型利用学习Infomax和领域无关表示的方法，通过最大化全局特征表示和个体特征表示之间的互信息，以及特征表示和治疗分配预测之间的互信息，来最大程度地捕捉治疗组和对照组的共同预测信息。具体而言，该模型首先学习一个表征映射R，映射后的表征根据处理进行加权平均得到S，模型通过损失惩罚使得R与S之间的信息达到最大（infomax），此外学习X的表征映射H并使得该映射能够预测T，并惩罚R和H直接的互信息以期R与领域选择无关。此外，本文还模仿GAN进行了判别器学习，通过判别随机打乱特征得到的R和正常的R来辅助训练。
    内容反思：本文针对现实世界数据中的因果推断挑战进行研究，特别是由于治疗选择偏差导致的协变量不平衡问题。现有的基于域不变表示学习的策略存在一些弱点，包括预测信息的丢失和不稳定的治疗效果估计。本文沿着领域迁移学习的思路进行了信息极大化，降低了噪声学习带来的影响，以提升模型稳健性。

6. Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model（2023）
  问题背景：CTR预估任务中，模型主要关注校准能力和排序能力，针对校准能力主要优化方法仍然以pointwise loss为主，原因在于其学习到的预测值可以直接看做是点击率预估值；针对排序能力则主要使用pairwise或listwise loss，它们具备更好的排序能力，能够更好地学习到用户的偏好，但是输出的预测值只反映了相对序而不能作为CTR预估值。
  文章内容：本文提出了一种名为联合优化排序和校准的上下文化混合模型（JRC）的方法，模型如下图(c)，以综合提高点击率预测模型的排序和校准能力。该方法将校准的点对点损失和排序的点对或列表损失相结合。它引入了二维logits来表示点击和非点击状态，并根据这些logits的差值计算预测的点击概率。输出的2维logit分别代表不点击(nonclick-logit)和点击(click-logit)，这样可以基于这两个logits来构造校准目标和排序目标。一方面，模型能够通过减法操作来融合这两个logit，采用这两个logit的差值接一个sigmoid函数得到概率估计，使得两个logits都会对最终的预测值有影响，用于CTR预估和最终线上打分；同时，为了提升相同context下的排序能力，本文采用listwise-like loss，在同一context(z)下，使得正样本的logit的click-logit更大，负样本的nonclick-logit更大，融合两个目标得到最终组合目标。
    内容反思：若直接使用1个logit构造交叉熵损失用于校准优化、1个logit构造listwise排序损失用户排序优化，会造成两个logit之间没有直接联系，也难以融合形成最终的预测，融合值也无法直接用于预估CTR。本文结合生成式和判别式的思想，用了两维的logit，分别组合成校准目标（判别式）和排序目标（生成式），通过引入额外的1个自由度，较好地缓解了排序目标和校准目标的冲突性，使得最终线上指标得以提升。

7. Invariant Risk Minimization（2020）
  问题背景：传统机器学习存在的问题是通过最小化训练误差来学习复杂的预测规则，但数据往往受到选择偏差和特殊性的影响，这导致过度依赖数据偏差，模型外推不够稳健。
  文章内容：本文模型不变风险最小化（IRM）提出使用因果关系来进行虚假和不变相关性的学习，以缓解上述问题，IRM促进学习在训练环境中稳定的相关性，从而实现对新的测试分布的泛化。模型目标是找到一种数据表示，使其上面的最优分类器在所有环境中都匹配，此外，本文介绍了一个约束优化问题，用于估计这样的预测器，并提出了一个双层实际版本（两级优化问题），并将之简化为了单目标问题，该方法平衡了预测能力和不变性，从而完成了对上述IRM思路的一种实践。
  内容反思：针对领域迁移问题中的环境噪声问题，简单来说，IRM的目标就是学习不同训练环境中不变的相关性。对于预测问题，这就意味这需要找到一种数据表达，使得在该数据表达之上的最佳分类器在不同的环境中都相同。这一思想在因果领域上同样有实践意义，后续Infomax、Information Bottleneck都是在此思想基础上构建的。理想情况下，通过不变特征和可变特征的构建，我们能找到更好的领域迁移方式，并将之平移到因果效应模型中代替表征平衡部分。

8. Invariant Information Bottleneck for Domain Generalization（2022）
  问题背景：在实际应用中，训练数据和测试数据往往不满足独立同分布（i.i.d.）的假设，导致经典的统计学习算法在面对不同领域的数据时性能下降。传统的领域泛化方法包括数据操作、集成学习和元学习等，但这些方法在处理非线性分类器、伪不变特征和几何偏差等问题时存在局限性。
  文章内容：本文提出不变信息瓶颈（IIB）方法，通过最小化不变风险和约束输入与表示之间的互信息来改善领域泛化的性能，通过互信息进行不变的因果预测。本文模型如下图所示，具体损失如下式，其中第一项和第三项是information bottleneck，第二项是IRM 准则，该公式即为IIB准则，通过该损失将模型训练成三个部分：(1)不变预测器fi(Z) ；(2)域依赖的预测器fd(Z,D)；(3)encoder g(X)。
    内容反思：本文从IRM的缺点出发，即可能依赖于伪一致性特征以及对于非线性分类器，损失函数难以优化，对此问题本文提出的模型分离出了不变预测器和域依赖预测器，通过互信息损失使得域信息和不变预测器进行解耦合。将其思想平移到因果推断领域中，我们可以通过构造不变学习器来学习不变表征，通过这一思想尝试替代强行表征平衡的方法，使用互信息对表征提取器进行训练，进而使得模型能够合理地提取不变域中的特征，提高模型对因果效应的感知度。

9. Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks（2019）
  问题背景：过去解决样本选择偏差的方案中，用于在观测数据上训练神经网络进行反事实推断的方法要么过于复杂，要么仅适用于仅有两种可用治疗方法的情况，或者两者兼而有之。
  文章内容：鉴于当前方法的局限性，本文引入了一种名为Perfect Match（PM）的简单方法，用于训练神经网络进行反事实推断，该方法适用于任意数量的处理方法。PM通过将每个小批量样本与其他治疗方法的倾向得分最接近的匹配样本进行增强，有效地控制了观测数据中治疗方法分配的偏差。PM易于使用现有的神经网络架构，实现简单，不增加任何超参数或计算复杂性。模型训练时，每一个进去训练batch的样本不只由真实的样本组成，还会通过倾向分（PS）去生成一些假样本，这个过程即为PM。对于每一个样本X，有一个他实际的处理t，我们需要找到这个样本另外k-1个处理的match。
  内容反思：PM方法提供了一种简单易嵌入的改进模块，其可以替换不稳定加权（batch内先验逆概率加权或基于PS的加权）来处理样本分布不均衡和选择偏差的问题，但是本文中的实验模拟部分使用的指标为通过根据平衡分数在训练数据中的最近邻的反事实结果进行插补，这个指标生成方法和文章所提出的改进方法有重叠，其所得结论未必有效。

10. Multi-Task Adversarial Learning for Treatment Effect Estimation in Basket Trials（2022）
  问题背景：传统的因果推断问题。
  文章内容：本文提出了MTAL方法，如下图所示，由结果生成器和真假（TF）判别器组成。结果生成器估计每个单位在所有处理对应的潜在结果，而TF判别器消除处理选择偏差并提高预测准确性。MTAL方法使用类似Tarnet的多头深度网络，并结合深度特征选择层，为每种处理选择适当的预测因子。该方法还采用对抗学习来优化结果生成器和TF判别器。训练过程使用极小极大决策规则来平衡结果生成器和判别器之间的权衡。

    内容反思：本文的技术方案类似结合了Tarnet和GANITE，并且将其向多处理场景进行了推广。其基础的推断网络架构和Tarnet极为类似，而其生成反事实样本并采用判别器进行对抗的方式也借鉴了GANITE的思想结构，但其训练过程的极小极大决策规则与原先策略略有不同，实际代码体现未见改进。

11. Decision-Making Context Interaction Network for Click-Through Rate Prediction（2023）
  问题背景：点击率预测对于推荐和在线广告系统至关重要。然而，现有的方法通常只关注用户行为模型，而忽视了影响用户点击决策的信息上下文，导致性能不佳。
  文章内容：提出决策上下文交互网络（DCIN）进行建模，模型流程图如下。大体上，DCIN使用topK自注意力机制筛选最有价值的显/隐性决策上下文，并在上下文交互模块进一步融合决策信息，从而提取用户历史决策过程的准确表达；具体而言，DCIN设计了CIU来建模每个page中被点击物品和其他物品的无关抑制/相关激活（显式建模），该模块由两个组件组成：无关性抑制单元（ISU）和相关性交互单元（RIU）。ISU抑制来自无关的页面内项目的影响，而RIU通过与相关页面内项目的显式上下文交互来增强用户行为兴趣。提取表征后再保留topk，去除其他来抑制不感兴趣物品，再采用注意力机制进行特征提取，并通过同样的方式在候选集上进行特征提取（隐式建模），得到的两个特征进过AIAU单元来进行注意力机制交互和前向网络特征提取，并最终与用户、物品、上下文特征一起送入分类层进行分类。
    内容反思：本文通过利用显式和隐式上下文产生增强的行为兴趣和精炼的目标，利用了page中的点击进行兴趣建模，分为显式的用户历史点击兴趣建模以及隐式的候选物品兴趣建模，再通过交互层对两者进行合并，最后与其他特征一起进行预测。这样使得模型能够以相似的方式进行用户的历史兴趣和候选潜在兴趣建模，细节上通过取topk物品进行了不感兴趣抑制，缩小了模型感知范围，提高模型的鲁棒性。

12. Improving Deep Learning For Airbnb Search（2019）
  问题背景：推荐系统中位置对于用户的点击、转化行为影响较大，通过模型进行去偏对于分数预估有重大意义。
  文章内容：给定一个用户 ，以及一个query 和一个list ，以及list中的每个位置 。用户预订的概率是：
    其中前半部分是这个item被用户预订的概率，后半部分是item在位置k被用户看到的概率。二者相乘就是一个item在位置k上被预订的概率。理想情况下我们只要关注于前半部分然后对list进行排序就OK。Airbnb在训练时加入位置信息，但是在预估的时候将特征置为0。但是发现模型的NDCG跌了1.3%。文章指出，可能是训练的时候相关性的计算过度依赖位置信息，但是在测试的时候，这个位置信息就没有了，所以导致效果变差。为了减少相关性计算对position feature的依赖，文章采用了训练阶段对position feature进行dropout，这样就能够减少模型对位置特征的依赖。通过实验文章选择了0.15的dropout比例，对线上的结果有0.7%的下单率的提升。经过多次迭代之后，订单收入涨了1.8%。需要注意的是位置特征不能与其他特征做交叉。
  文章反思：由于位置偏差的存在，离线训练模型到线上预估往往会存在gap，本文提出通过dropout减轻模型对位置特征的依赖来抵消这个gap，取得了不错的效果。

13. Recommending What Video to Watch Next: A Multitask Ranking System（2019）
  问题背景：（同上）推荐系统中位置对于用户的点击、转化行为影响较大，通过模型进行去偏对于分数预估有重大意义。
  文章内容：本文提出了MMoE多任务架构，该系统应用于视频推荐，目标是根据用户当前的观看情况推荐下一个要观看的视频，但我们更关心其对于位置偏差的debias部分。对于这一问题，本文提出浅塔（shallow tower）架构，如下图所示，该架构用于建模和消除选择偏见，该塔对位置信息和相关其他特征进行交互，利用更多的位置信息，其中还包含设备信息（不同设备即使是同一个位置对用户感知可能有差异的），并且位置信息之间会有交叉操作。训练的时候将交叉后的位置信息进行前向处理，输出一个logit，与排序的logit直接相加。值得一提的是本文也采用了对位置信息塔10%的dropout来避免模型对于位置信息的过度依赖。
    文章反思：本文对于位置偏差处理的方式与Airbnb不同之处在于采用了一个浅层塔来对位置信息对其他特征进行交互，这样使得位置信息的利用率大幅提升，无疑会提高模型对ctr的拟合能力，但是这一方式并未能缓解到线上推理的bias，原因在于其位置信息在训练中存在到推理时不存在的gap仍未解决，且模型更加依赖位置信息，可能会增强这一bias。此外，本文也采用了对position的dropout来减弱模型对于位置信息的依赖，一定程度上缓解bias。

14. PAL: A Position-bias Aware Learning Framework for CTR Prediction in Live Recommender Systems（2019）
  问题背景：过去的解决方案中，一种常见的方法是将位置信息作为特征进行建模，但由于在线推断时无法获取实际位置信息，需要使用默认的位置值进行预测。然而，不同的默认位置值可能导致完全不同的推荐结果，从而降低了在线性能。（即position bias）
  文章内容：提出PAL模型，如下图左所示。该模型假设用户点击可以拆解为用户查看和用户查看后点击，即有p(y=1∣x,pos)=p(seen∣pos)*p(y=1∣x,seen)，并通过双塔分别建模p(seen∣pos)和p(y=1∣x,seen)，其中第一项用position来建模，第二项用其余特征来建模，在推理时仅用右边的塔（即假设被看到的概率相同时的CTR）。
    文章反思：本文实际上有点像注意力机制，条件概率的前一项可理解为用户对于该位置的倾向性，或者用户对于该位置的注意力系数，用该系数乘上后一项即为最终预测概率，其解耦的思想能够更好地建模debias后的ctr分数（注意该预测值不能直接视作ctr，因为少了前一项的先验概率，或者认为该先验概率已设为1）。但是本模型也存在一些可改进点，如位置塔中可以加入位置信息和用户、设备信息的交互；此外，PAL的乘积假设有些严格，实际上可能与该假设相悖进而无法解耦。

15. Deep Position-wise Interaction Network for CTR Prediction（2021）
  问题背景：点击数据本质上偏向于较高的位置，因此CTR模型的训练存在偏差问题。过去的方法在训练和推断中对位置信息的处理不一致，导致在线性能不一致和次优。此外，这些方法的基本假设过于简化，无法充分建模位置与其他信息之间的丰富交互。（即position bias）
  文章内容：本文提出了一种新的CTR预测方法，即深度位置交互网络（DPIN）。该方法通过有效地结合候选项和位置来估计每个位置的CTR，实现了离线和在线一致性，并在服务性能限制下对位置、用户、上下文和项目之间的深度非线性交互进行建模。具体而言，其包括三个组件：Position-wise Interest Aggregation、Position-wise Non-linear Interaction和Transformer Block，Position-wise Interest Aggregation独立地检索每个位置的用户行为序列，以消除位置偏差。使用上下文感知的注意机制提取与当前上下文相关的用户兴趣；Position-wise Non-linear Interaction组件使用具有ReLU激活函数的全连接层来捕捉位置、上下文和用户之间的非线性交互；Transformer Block用于实现不同位置之间的交互。它使用多头自注意力机制来捕捉位置之间的依赖关系，并使用位置感知的前馈网络进行非线性变换。
    文章反思：本文DPIN提供了一种一次性估计物品在各个位置上ctr概率的方法，这种方式在训练时使用位置信息，在预测时去除位置信息，可以较好地抵消位置偏差带来的影响。传统的ctr预估中，理想中的去除位置偏差的方式是预估每个物品在每个位置上的ctr，但是这样的话推理复杂度较高，本文的思想是采用多头网络减少这个复杂度，有点类似因果推断中的反事实估计，通过shared bottom机制减小训练难度和推理复杂度。

16. MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask（2021）
  问题背景：对于排序模型（CTR预估）来说，有效地捕捉复杂的高阶特征非常重要，过去的研究表明，传统的特征交互方法，特别是简单前馈神经网络（DNN），对于捕捉常见的特征交叉效果不佳。
  文章内容：尝试通过引入特定的乘法操作来改进DNN排序系统，以更有效地捕捉复杂的特征交互，基于此思想提出了如下图左的MaskBlock，在传统的Embedding提取层后接入一个额外的层来提取特征重要性，该层通过一个全连接层和一个LayerNormalization构成，并用该重要性与全连接层输出进行点乘，得到基于Mask（或者说基于特征重要性）的前馈输出。基于MaskBlock，用相同的思想进行多次特征重要性的点乘操作，即得到如下图右的MaskBlock on MaskBlock。通过这一类Block，本文提出了两种MLP结构，一种是串行多个Block的序列网络，另一种是并行多个Block的平行网络（如下图）。
    内容反思：本文所关注的点比较通用，聚焦在对于传统MLP的改进，改进的方式类似注意力机制，也像自交叉的操作，通过自身（或者底层特征或是先验信息）额外构造特征权重层，并利用该层进行类注意力的点乘操作，较之一般的MLP通过额外增加参数量达到提高模型性能的效果，其中对于本文所提出的MaskBlock的使用方式，串行类似残差链接，每一次都使用原本的信息构建特征权重，并行则类似多头自注意力操作，在不同的仿射空间上进行基于特征重要性的点乘操作来提取不同空间上的特征。

17. FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction（2023）
  问题背景：在CTR预估任务中，为了增强学习显式特征交互，已经提出了许多双流交互模型，如DeepFM和DCN。然而，现有研究主要集中在增强补充流中的显式特征交互，而对于MLP流隐式学习的特征交互，现有研究关注较少。
  文章内容：本文提出了特征选择和交互聚合层，以构建一个增强的双流MLP模型FinalMLP，模型结构如下图中所示。特征选择层是本文的第一个重点，如下图左所示，对于每一个MLP，学习一个Gate，Gate的输入是定制化的一些特征（在本文中使用了用户特征学习和item特征学习）。这样通过gate就能让两个MLP关注的信息存在差异，一个更关注用户侧特征，另一个更关注item侧特征。Fusion层是本文的第二个重点，主要作用是完成两个MLP输出的交叉。一般情况，两个MLP的输出会直接做concat或者sum（Wide & Deep、DeepFM等），但是FinalMLP模型进行了如下公式的交互作为输出层，并在实际中提出分多头进行乘法交互，以平衡乘法参数过多所带来的训练稳定性压力。
      内容反思：本文通过两个插入模块对双流MLP做出了改进，基模型双流MLP通过两个并行（且平行）MLP分别生成输出并相加得到结果，而这种方法不仅没有使得两个MLP在不同空间上抽取信息，也没有进行交互。本文的思路先是从输入上通过不同先验特征做embedding的筛选，之后在输出层上采用基于注意力机制的乘法交互，这样使得模型能够更好地提取不同仿射空间上的特征，并进行交互；除此之外，在输出交互层上的多头设置很像多头自注意力，该方式不仅减少了参数量，还提高了模型稳定性和泛化性能。